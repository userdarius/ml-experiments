{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPP6ujCGwg/7W/nCfLnxu1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/userdarius/ml-experiments/blob/main/AlexNetMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyKzD6UWVkbI",
        "outputId": "a2eeb99e-ddaf-4837-929b-3657392b63b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "# 3rd party\n",
        "import numpy as np\n",
        "\n",
        "# We import PyTorch and some of its internal modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "from torchinfo import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Project files.\n",
        "from helpers import accuracy, DrawingPad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4dRgt0pV0yg",
        "outputId": "ed03cfc2-889a-4f27-c365-b3bef6146615"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Dataset and DataLoader for MLP.\n",
        "dataset_train = MNIST('data', train=True, download=True, transform=ToTensor())\n",
        "dataset_test = MNIST('data', train=False, download=True, transform=ToTensor())\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Loaded {} train and {} valid samples.'.format(len(dataset_train), len(dataset_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xAvmJ_aoV86u",
        "outputId": "eefa5a36-2c06-44f6-ccb1-200981a4d485"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 60000 train and 10000 valid samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss fuction.\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2u--hwC6WB4t"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, dataloader_train, dataloader_test, epochs):\n",
        "    \"\"\" Trains the model for the specified number of epochs on the dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        criterion: The loss function.\n",
        "        optimizer: The optimizer to use.\n",
        "        dataloader_train: The DataLoader for the training set.\n",
        "        dataloader_test: The DataLoader for the test set.\n",
        "        epochs: The number of epochs to train for.\n",
        "    \"\"\"\n",
        "    for ep in range(epochs):\n",
        "        # Training.\n",
        "        model.train()\n",
        "        for it, batch in enumerate(dataloader_train):\n",
        "\n",
        "            # 5.1 Load a batch, break it down in images and targets.\n",
        "            x, y = batch\n",
        "\n",
        "            # load to cuda\n",
        "            if torch.cuda.is_available():\n",
        "              x = x.cuda()  # Move inputs to GPU\n",
        "              y = y.cuda()  # Move labels to GPU\n",
        "\n",
        "            # 5.2 Run forward pass.\n",
        "            logits = model(x)\n",
        "\n",
        "            # 5.3 Compute loss (using 'criterion').\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            # 5.4 Run backward pass.\n",
        "            loss.backward()\n",
        "\n",
        "            # 5.5 Update the weights using 'optimizer'.\n",
        "            optimizer.step()\n",
        "\n",
        "            # 5.6 Zero-out the accumulated gradients.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            print('\\rEp {}/{}, it {}/{}: loss train: {:.2f}, accuracy train: {:.2f}'.\n",
        "                  format(ep + 1, epochs, it + 1, len(dataloader_train), loss,\n",
        "                         accuracy(logits, y)), end='')\n",
        "\n",
        "        # Validation.\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            acc_run = 0\n",
        "            for it, batch in enumerate(dataloader_test):\n",
        "                # Get batch of data.\n",
        "                x, y = batch\n",
        "                if torch.cuda.is_available():\n",
        "                  x = x.cuda()\n",
        "                  y = y.cuda()\n",
        "                curr_bs = x.shape[0]\n",
        "                acc_run += accuracy(model(x), y) * curr_bs\n",
        "            acc = acc_run / len(dataloader_test.dataset)\n",
        "\n",
        "            print(', accuracy test: {:.2f}'.format(acc))"
      ],
      "metadata": {
        "id": "TFcvqJ4tWHR1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified AlexNet implementation for MNIST\n",
        "class alexNet(nn.Module):\n",
        "    \"\"\" Build your own model.\n",
        "    It should take as input images of shape (1, 28, 28).\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize your model.\n",
        "\n",
        "        Feel free to add argument if you want to.\n",
        "        \"\"\"\n",
        "        super(alexNet, self).__init__()\n",
        "\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(32*12*12,2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048,1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024,10),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define the forward pass of your model.\n",
        "\n",
        "        Args:\n",
        "        x: torch.Tensor of shape (batch_size, 1, 28, 28)\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor of shape (batch_size, 10)\n",
        "        \"\"\"\n",
        "        x = self.feature(x)\n",
        "        x = x.view(-1,32*12*12)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "neTiMZoYWLzG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model and print its architecture.\n",
        "model = alexNet()\n",
        "summary(model, input_size=(1, 1, 28, 28))\n",
        "\n",
        "# Train your model.\n",
        "epochs = 5\n",
        "learning_rate = 1e-1\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "train_model(model, criterion, optimizer, dataloader_train, dataloader_test, epochs)\n",
        "\n",
        "train_losses = []\n",
        "test_losses =[]\n",
        "test_accuracy = []\n",
        "\n",
        "# Add graphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QM84MK8JWTz7",
        "outputId": "f6e54241-8c6c-4787-a169-4b76b687bb34"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/5, it 469/469: loss train: 2.29, accuracy train: 0.18, accuracy test: 0.22\n",
            "Ep 2/5, it 469/469: loss train: 0.13, accuracy train: 0.95, accuracy test: 0.97\n",
            "Ep 3/5, it 469/469: loss train: 0.12, accuracy train: 0.96, accuracy test: 0.98\n",
            "Ep 4/5, it 469/469: loss train: 0.07, accuracy train: 0.98, accuracy test: 0.99\n",
            "Ep 5/5, it 469/469: loss train: 0.02, accuracy train: 0.99, accuracy test: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3XzrSutcTeS"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}